{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MacGNN Demo Notebook (Optimized & Self-Contained)\n",
    "This notebook has been optimized to include all necessary model definitions and utility functions without external Python file dependencies. It also adds support for macOS MPS (Metal Performance Shaders) acceleration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "1. Ensure the `data/` directory contains the corresponding dataset `*.pkl` files.\n",
    "2. Simply run the code cells below to start training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-deps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies for this notebook\n",
    "%pip install -q -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tqdm\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gauc_metric",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_group_auc(labels, preds, user_id_list):\n",
    "    \"\"\"\n",
    "    Calculate Group AUC (GAUC) metric for recommendation systems.\n",
    "    \n",
    "    GAUC computes AUC separately for each user and averages them,\n",
    "    weighted by sample count. Better reflects ranking performance\n",
    "    than global AUC in personalized recommendations.\n",
    "    \"\"\"\n",
    "    if len(user_id_list) != len(labels):\n",
    "        raise ValueError(\n",
    "            \"impression id num should equal to the sample num,\" \\\n",
    "            \"impression id num is {0}\".format(len(user_id_list)))\n",
    "    group_score = defaultdict(lambda: [])\n",
    "    group_truth = defaultdict(lambda: [])\n",
    "    for idx, truth in enumerate(labels):\n",
    "        user_id = user_id_list[idx]\n",
    "        score = preds[idx]\n",
    "        truth = labels[idx]\n",
    "        group_score[user_id].append(score)\n",
    "        group_truth[user_id].append(truth)\n",
    "\n",
    "    group_flag = defaultdict(lambda: False)\n",
    "    for user_id in set(user_id_list):\n",
    "        truths = group_truth[user_id]\n",
    "        flag = False\n",
    "        for i in range(len(truths) - 1):\n",
    "            if truths[i] != truths[i + 1]:\n",
    "                flag = True\n",
    "                break\n",
    "        group_flag[user_id] = flag\n",
    "\n",
    "    impression_total = 0\n",
    "    total_auc = 0.0\n",
    "    #\n",
    "    for user_id in group_flag:\n",
    "        if group_flag[user_id]:\n",
    "            auc = roc_auc_score(np.asarray(group_truth[user_id]), np.asarray(group_score[user_id]))\n",
    "            total_auc += auc * len(group_truth[user_id])\n",
    "            impression_total += len(group_truth[user_id])\n",
    "    if impression_total == 0:\n",
    "        return None\n",
    "    group_auc = float(total_auc) / impression_total\n",
    "    group_auc = round(group_auc, 5)\n",
    "    return group_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bec125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Dice, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.zeros((1, )))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg = x.mean(dim=0)\n",
    "        std = x.std(dim=0)\n",
    "        norm_x = (x - avg) / (std + 1e-8)\n",
    "        p = torch.sigmoid(norm_x)\n",
    "\n",
    "        return x.mul(p) + self.alpha * x.mul(1 - p)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d389f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Baseline models (DeepFM, DIN, DIEN) loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# Baseline Models for Comparison\n",
    "# ===========================================\n",
    "\n",
    "class FeaturesLinear(nn.Module):\n",
    "    \"\"\"Linear part for DeepFM\"\"\"\n",
    "    def __init__(self, field_dims, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Embedding(sum(field_dims), output_dim)\n",
    "        self.bias = nn.Parameter(torch.zeros((output_dim,)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sum(self.fc(x), dim=1) + self.bias\n",
    "\n",
    "\n",
    "class FeaturesEmbedding(nn.Module):\n",
    "    \"\"\"Embedding layer for all models\"\"\"\n",
    "    def __init__(self, field_dims, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "class FactorizationMachine(nn.Module):\n",
    "    \"\"\"FM layer for DeepFM\"\"\"\n",
    "    def __init__(self, reduce_sum=True):\n",
    "        super().__init__()\n",
    "        self.reduce_sum = reduce_sum\n",
    "        \n",
    "    def forward(self, x):\n",
    "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "        ix = square_of_sum - sum_of_square\n",
    "        if self.reduce_sum:\n",
    "            ix = torch.sum(ix, dim=1, keepdim=True)\n",
    "        return 0.5 * ix\n",
    "\n",
    "\n",
    "class DeepFM(nn.Module):\n",
    "    \"\"\"\n",
    "    DeepFM: A Factorization-Machine based Neural Network for CTR Prediction\n",
    "    Only uses user and item features (simplified for fair comparison)\n",
    "    \"\"\"\n",
    "    def __init__(self, field_dims, embed_dim, mlp_dims=(400, 400, 400), dropout=0.0):\n",
    "        super().__init__()\n",
    "        # Only use user and item (first 2 fields)\n",
    "        self.simple_field_dims = field_dims[:2]\n",
    "        self.embedding = FeaturesEmbedding(self.simple_field_dims, embed_dim)\n",
    "        self.linear = FeaturesLinear(self.simple_field_dims)\n",
    "        self.fm = FactorizationMachine(reduce_sum=True)\n",
    "        \n",
    "        mlp_layers = []\n",
    "        input_dim = len(self.simple_field_dims) * embed_dim\n",
    "        for mlp_dim in mlp_dims:\n",
    "            mlp_layers.append(nn.Linear(input_dim, mlp_dim))\n",
    "            mlp_layers.append(nn.BatchNorm1d(mlp_dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(dropout))\n",
    "            input_dim = mlp_dim\n",
    "        mlp_layers.append(nn.Linear(input_dim, 1))\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract only user and item\n",
    "        x_simple = x[:, [0, 1 + x.shape[1]//2]]  # user_id and item_id\n",
    "        embed_x = self.embedding(x_simple)\n",
    "        x = self.linear(x_simple) + self.fm(embed_x) + self.mlp(embed_x.view(embed_x.size(0), -1))\n",
    "        return torch.sigmoid(x.squeeze(1))\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    \"\"\"Attention mechanism for DIN\"\"\"\n",
    "    def __init__(self, embed_dim, hidden_dim=80):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 4, hidden_dim),\n",
    "            Dice(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, query, keys, keys_length):\n",
    "        batch_size, max_length, embed_dim = keys.size()\n",
    "        query = query.unsqueeze(1).expand(-1, max_length, -1)\n",
    "        \n",
    "        # attention input: [query, keys, query-keys, query*keys]\n",
    "        din_all = torch.cat([query, keys, query - keys, query * keys], dim=-1)\n",
    "        outputs = self.attention(din_all)\n",
    "        \n",
    "        # Mask padding\n",
    "        mask = (torch.arange(max_length).unsqueeze(0).to(keys.device) < keys_length.unsqueeze(1)).unsqueeze(-1)\n",
    "        outputs = outputs.masked_fill(~mask, -1e9)\n",
    "        \n",
    "        # Weighted sum\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        outputs = torch.sum(outputs * keys, dim=1)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "class DIN(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Interest Network for CTR prediction\n",
    "    Uses attention to capture user interests from behavior sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, field_dims, embed_dim, recent_len, mlp_dropout=0.0, raw_recent_len=None):\n",
    "        super().__init__()\n",
    "        self.user_embed = nn.Embedding(field_dims[0], embed_dim)\n",
    "        self.item_embed = nn.Embedding(field_dims[1], embed_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.item_embed.weight.data)\n",
    "        \n",
    "        self.raw_recent_len = raw_recent_len if raw_recent_len is not None else recent_len\n",
    "        self.recent_len = max(1, min(recent_len, self.raw_recent_len))\n",
    "        \n",
    "        self.attention = AttentionPooling(embed_dim, hidden_dim=80)\n",
    "        \n",
    "        mlp_layers = [\n",
    "            nn.Linear(embed_dim * 3, 200),\n",
    "            Dice()\n",
    "        ]\n",
    "        if mlp_dropout > 0:\n",
    "            mlp_layers.append(nn.Dropout(mlp_dropout))\n",
    "        mlp_layers.extend([\n",
    "            nn.Linear(200, 80),\n",
    "            Dice()\n",
    "        ])\n",
    "        if mlp_dropout > 0:\n",
    "            mlp_layers.append(nn.Dropout(mlp_dropout))\n",
    "        mlp_layers.append(nn.Linear(80, 1))\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract user, item, and recent sequence\n",
    "        user_id = x[:, 0]\n",
    "        # Find item position (after user + neighbors)\n",
    "        item_pos = 1 + x.shape[1] // 2\n",
    "        item_id = x[:, item_pos]\n",
    "        \n",
    "        # Recent items are before item_id\n",
    "        recent_start = item_pos - self.raw_recent_len\n",
    "        user_recent = x[:, recent_start:item_pos][:, -self.recent_len:]\n",
    "        \n",
    "        user_emb = self.user_embed(user_id)\n",
    "        item_emb = self.item_embed(item_id)\n",
    "        hist_emb = self.item_embed(user_recent)\n",
    "        \n",
    "        # Calculate sequence length (non-zero items)\n",
    "        hist_len = (user_recent > 0).sum(dim=1)\n",
    "        \n",
    "        # Attention pooling\n",
    "        hist_pooled = self.attention(item_emb, hist_emb, hist_len)\n",
    "        \n",
    "        # Concatenate and predict\n",
    "        concat = torch.cat([user_emb, item_emb, hist_pooled], dim=1)\n",
    "        output = self.mlp(concat)\n",
    "        return torch.sigmoid(output.squeeze(1))\n",
    "\n",
    "\n",
    "class GRUCell(nn.Module):\n",
    "    \"\"\"GRU with interest evolution for DIEN\"\"\"\n",
    "    def __init__(self, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        output, hidden = self.gru(packed)\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class DIEN(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Interest Evolution Network\n",
    "    Models the evolution of user interests over time\n",
    "    \"\"\"\n",
    "    def __init__(self, field_dims, embed_dim, recent_len, mlp_dropout=0.0, raw_recent_len=None):\n",
    "        super().__init__()\n",
    "        self.user_embed = nn.Embedding(field_dims[0], embed_dim)\n",
    "        self.item_embed = nn.Embedding(field_dims[1], embed_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.item_embed.weight.data)\n",
    "        \n",
    "        self.raw_recent_len = raw_recent_len if raw_recent_len is not None else recent_len\n",
    "        self.recent_len = max(1, min(recent_len, self.raw_recent_len))\n",
    "        \n",
    "        # Interest extractor\n",
    "        self.interest_gru = GRUCell(embed_dim, embed_dim)\n",
    "        \n",
    "        # Interest evolution with attention\n",
    "        self.evolution_attention = AttentionPooling(embed_dim, hidden_dim=80)\n",
    "        \n",
    "        mlp_layers = [\n",
    "            nn.Linear(embed_dim * 3, 200),\n",
    "            Dice()\n",
    "        ]\n",
    "        if mlp_dropout > 0:\n",
    "            mlp_layers.append(nn.Dropout(mlp_dropout))\n",
    "        mlp_layers.extend([\n",
    "            nn.Linear(200, 80),\n",
    "            Dice()\n",
    "        ])\n",
    "        if mlp_dropout > 0:\n",
    "            mlp_layers.append(nn.Dropout(mlp_dropout))\n",
    "        mlp_layers.append(nn.Linear(80, 1))\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        user_id = x[:, 0]\n",
    "        item_pos = 1 + x.shape[1] // 2\n",
    "        item_id = x[:, item_pos]\n",
    "        \n",
    "        recent_start = item_pos - self.raw_recent_len\n",
    "        user_recent = x[:, recent_start:item_pos][:, -self.recent_len:]\n",
    "        \n",
    "        user_emb = self.user_embed(user_id)\n",
    "        item_emb = self.item_embed(item_id)\n",
    "        hist_emb = self.item_embed(user_recent)\n",
    "        \n",
    "        hist_len = (user_recent > 0).sum(dim=1)\n",
    "        hist_len = torch.clamp(hist_len, min=1)  # Avoid zero length\n",
    "        \n",
    "        # Interest extraction\n",
    "        interests, _ = self.interest_gru(hist_emb, hist_len)\n",
    "        \n",
    "        # Interest evolution with attention\n",
    "        final_interest = self.evolution_attention(item_emb, interests, hist_len)\n",
    "        \n",
    "        concat = torch.cat([user_emb, item_emb, final_interest], dim=1)\n",
    "        output = self.mlp(concat)\n",
    "        return torch.sigmoid(output.squeeze(1))\n",
    "\n",
    "\n",
    "print(\"âœ… Baseline models (DeepFM, DIN, DIEN) loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetBuilder(torch.utils.data.Dataset):\n",
    "    \"\"\"PyTorch Dataset for MacGNN training and evaluation.\"\"\"\n",
    "\n",
    "    def __init__(self, data, user_count, item_count):\n",
    "        self.x = torch.tensor(data[:, :-1], dtype=torch.long)\n",
    "        self.y = torch.tensor(data[:, -1], dtype=torch.float)\n",
    "        self.field_dims = [user_count, item_count]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "macgnn",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborAggregation(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim=8, hidden_dim=8):\n",
    "        super(NeighborAggregation, self).__init__()\n",
    "        self.Q_w = nn.Linear(embed_dim, hidden_dim, bias=False)\n",
    "        self.K_w = nn.Linear(embed_dim, hidden_dim, bias=False)\n",
    "        self.V_w = nn.Linear(embed_dim, hidden_dim, bias=False)\n",
    "        self.trans_d = math.sqrt(hidden_dim)\n",
    "        self.get_score = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        trans_Q = self.Q_w(query)\n",
    "        trans_K = self.K_w(key)\n",
    "        trans_V = self.V_w(query)\n",
    "        score = self.get_score(torch.bmm(trans_Q, torch.transpose(trans_K,1,2))/(self.trans_d))\n",
    "        answer = torch.mul(trans_V, score)\n",
    "        return answer\n",
    "\n",
    "\n",
    "class MacGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Micro-macro Consumer Graph Neural Network for CTR prediction.\n",
    "    \n",
    "    Combines:\n",
    "    - User/item embeddings\n",
    "    - Macro-level cluster embeddings (u_macro, i_macro)\n",
    "    - Neighbor aggregation via attention mechanism\n",
    "    - Recent behavior sequences\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dims, u_group_num, i_group_num, embed_dim, recent_len, tau=0.8, device='cpu', mlp_dropout=0.0, raw_recent_len=None):\n",
    "        super(MacGNN, self).__init__()\n",
    "        self.user_embed = nn.Embedding(field_dims[0], embed_dim)\n",
    "        self.item_embed = nn.Embedding(field_dims[1], embed_dim)\n",
    "        self.cate_embed = nn.Embedding(field_dims[2], embed_dim)\n",
    "        self.u_macro_embed = nn.Embedding(u_group_num + 1, embed_dim)\n",
    "        self.i_macro_embed = nn.Embedding(i_group_num + 1, embed_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.item_embed.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.cate_embed.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.u_macro_embed.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.i_macro_embed.weight.data)\n",
    "        self.tau = tau\n",
    "        self.u_shared_aggregator = NeighborAggregation(embed_dim, 2 * embed_dim)\n",
    "        self.i_shared_aggregator = NeighborAggregation(embed_dim, 2 * embed_dim)\n",
    "        self.u_group_num = u_group_num + 1\n",
    "        self.i_group_num = i_group_num + 1\n",
    "        self.raw_recent_len = raw_recent_len if raw_recent_len is not None else recent_len\n",
    "        if self.raw_recent_len <= 0:\n",
    "            raise ValueError('raw_recent_len must be positive')\n",
    "        self.requested_recent_len = recent_len\n",
    "        self.recent_len = max(1, min(recent_len, self.raw_recent_len))\n",
    "        if self.recent_len != recent_len:\n",
    "            print(f\"[MacGNN] recent_len {recent_len} exceeds dataset limit {self.raw_recent_len}; using {self.recent_len}.\")\n",
    "        self.macro_weight_func = nn.Softmax(dim=1)\n",
    "        self.u_gruop_slice = torch.arange(self.u_group_num, requires_grad=False).to(device)\n",
    "        self.i_gruop_slice = torch.arange(self.i_group_num, requires_grad=False).to(device)\n",
    "        mlp_layers = [\n",
    "            nn.Linear(embed_dim * 14, 200),\n",
    "            Dice()\n",
    "        ]\n",
    "        if mlp_dropout > 0:\n",
    "            mlp_layers.append(nn.Dropout(mlp_dropout))\n",
    "        mlp_layers.extend([\n",
    "            nn.Linear(200, 80),\n",
    "            Dice()\n",
    "        ])\n",
    "        if mlp_dropout > 0:\n",
    "            mlp_layers.append(nn.Dropout(mlp_dropout))\n",
    "        mlp_layers.append(nn.Linear(80, 1))\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        offset = 0\n",
    "        user_embedding = self.user_embed(x[:, offset])\n",
    "        offset += 1\n",
    "\n",
    "        user_1ord_neighbor = x[:, offset: offset + self.i_group_num]\n",
    "        offset += self.i_group_num\n",
    "\n",
    "        user_2ord_neighbor = x[:, offset: offset + self.u_group_num]\n",
    "        offset += self.u_group_num\n",
    "\n",
    "        user_recent_block = x[:, offset: offset + self.raw_recent_len]\n",
    "        offset += self.raw_recent_len\n",
    "\n",
    "        item_embedding = self.item_embed(x[:, offset])\n",
    "        offset += 1\n",
    "\n",
    "        item_1ord_neighbor = x[:, offset: offset + self.u_group_num]\n",
    "        offset += self.u_group_num\n",
    "\n",
    "        item_2ord_neighbor = x[:, offset: offset + self.i_group_num]\n",
    "        offset += self.i_group_num\n",
    "\n",
    "        item_recent_block = x[:, offset: offset + self.raw_recent_len]\n",
    "\n",
    "        if self.recent_len < self.raw_recent_len:\n",
    "            user_recent = user_recent_block[:, -self.recent_len:]\n",
    "            item_recent = item_recent_block[:, -self.recent_len:]\n",
    "        else:\n",
    "            user_recent = user_recent_block\n",
    "            item_recent = item_recent_block\n",
    "\n",
    "        batch_u_gruop_slice = self.u_gruop_slice.expand(x.shape[0], self.u_group_num)\n",
    "        batch_i_gruop_slice = self.i_gruop_slice.expand(x.shape[0], self.i_group_num)\n",
    "\n",
    "        user_recent_mask = (user_recent > 0).float().unsqueeze(-1)\n",
    "        item_recent_mask = (item_recent > 0).float().unsqueeze(-1)\n",
    "        \n",
    "        user_1ord_weight = self.macro_weight_func(torch.log(user_1ord_neighbor.float()+1) / self.tau).unsqueeze(-1)\n",
    "        user_2ord_weight = self.macro_weight_func(torch.log(user_2ord_neighbor.float()+1) / self.tau).unsqueeze(-1)\n",
    "        item_1ord_weight = self.macro_weight_func(torch.log(item_1ord_neighbor.float()+1) / self.tau).unsqueeze(-1)\n",
    "        item_2ord_weight = self.macro_weight_func(torch.log(item_2ord_neighbor.float()+1) / self.tau).unsqueeze(-1)\n",
    "\n",
    "        user_1ord_embedding = self.i_macro_embed(batch_i_gruop_slice)\n",
    "        user_2ord_embedding = self.u_macro_embed(batch_u_gruop_slice)\n",
    "        item_1ord_embedding = self.u_macro_embed(batch_u_gruop_slice)\n",
    "        item_2ord_embedding = self.i_macro_embed(batch_i_gruop_slice)\n",
    "        user_recent_embedding = self.item_embed(user_recent)\n",
    "        item_recent_embedding = self.user_embed(item_recent)\n",
    "\n",
    "        u_1ord_trans_emb = self.i_shared_aggregator(user_1ord_embedding, item_embedding.unsqueeze(1))\n",
    "        u_2ord_trans_emb = self.u_shared_aggregator(user_2ord_embedding, user_embedding.unsqueeze(1))\n",
    "        i_1ord_trans_emb = self.u_shared_aggregator(item_1ord_embedding, user_embedding.unsqueeze(1))\n",
    "        i_2ord_trans_emb = self.i_shared_aggregator(item_2ord_embedding, item_embedding.unsqueeze(1))\n",
    "        user_recent_trans_emb = self.i_shared_aggregator(user_recent_embedding, item_embedding.unsqueeze(1))\n",
    "        item_recent_trans_emb = self.u_shared_aggregator(item_recent_embedding, user_embedding.unsqueeze(1))\n",
    "\n",
    "        user_1ord_ws = torch.mul(u_1ord_trans_emb, user_1ord_weight).sum(dim=1)\n",
    "        user_2ord_ws = torch.mul(u_2ord_trans_emb, user_2ord_weight).sum(dim=1)\n",
    "        item_1ord_ws = torch.mul(i_1ord_trans_emb, item_1ord_weight).sum(dim=1)\n",
    "        item_2ord_ws = torch.mul(i_2ord_trans_emb, item_2ord_weight).sum(dim=1)\n",
    "        user_recent_ws = torch.mul(user_recent_trans_emb, user_recent_mask).sum(dim=1)\n",
    "        item_recent_ws = torch.mul(item_recent_trans_emb, item_recent_mask).sum(dim=1)\n",
    "\n",
    "        concated = torch.hstack(\n",
    "            [user_embedding, user_1ord_ws, user_2ord_ws, user_recent_ws, item_embedding, item_1ord_ws, item_2ord_ws, \n",
    "             item_recent_ws])\n",
    "        output = self.mlp(concated)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "early_stopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper(object):\n",
    "\n",
    "    def __init__(self, num_trials, save_path):\n",
    "        self.num_trials = num_trials\n",
    "        self.trial_counter = 0\n",
    "        self.best_auc = 0.0\n",
    "        self.best_logloss = 1000000\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def is_continuable(self, model, auc, log_loss):\n",
    "        if auc > self.best_auc:\n",
    "            self.best_logloss = log_loss\n",
    "            self.best_auc = auc\n",
    "            self.trial_counter = 0\n",
    "            # Changed to save state_dict for security and portability\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            return True\n",
    "        elif self.trial_counter + 1 < self.num_trials:\n",
    "            self.trial_counter += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "train_eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with early stopping and optional LR scheduling\n",
    "def train(model, optimizer, train_data_loader, test_data_loader, criterion, device, early_stopper, epochs=10, test_iter=50, log_interval=20, scheduler=None):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    tk0 = tqdm.tqdm(train_data_loader, smoothing=0, mininterval=1.0)\n",
    "    now_iter = 0\n",
    "    break_flag = False\n",
    "    for epo in range(epochs):\n",
    "        for i, (fields, target) in enumerate(tk0):\n",
    "            model.train()\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            target = target.float().view(-1)\n",
    "            y = model(fields).view(-1)\n",
    "\n",
    "            loss = criterion(y, target)\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            now_iter += 1\n",
    "            \n",
    "            if now_iter % test_iter == 0:\n",
    "                # testing\n",
    "                auc, log_losses, _ = evaluation(model, test_data_loader, device, use_gauc=False)\n",
    "                if not early_stopper.is_continuable(model, auc, log_losses):\n",
    "                    print(f'validation: best auc: {early_stopper.best_auc}, best logloss: {early_stopper.best_logloss}')\n",
    "                    break_flag = True\n",
    "                    break\n",
    "            \n",
    "            if (i+1) % log_interval == 0:\n",
    "                # display\n",
    "                tk0.set_postfix(loss=total_loss / log_interval)\n",
    "                total_loss = 0\n",
    "                \n",
    "        if break_flag:\n",
    "            break\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "# Evaluation function: computes AUC, LogLoss, and optionally GAUC\n",
    "def evaluation(model, data_loader, device, use_gauc=False):\n",
    "    model.eval()\n",
    "    targets, predicts, user_id_list = list(), list(), list()\n",
    "    with torch.no_grad():\n",
    "        for fields, target in tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0):\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            y = model(fields)\n",
    "            user_id_list.extend(fields[:, 0].tolist())\n",
    "            targets.extend(target.tolist())\n",
    "            predicts.extend(y.tolist())\n",
    "    gauc = None\n",
    "    if use_gauc:\n",
    "        gauc = cal_group_auc(targets, predicts, user_id_list)\n",
    "    targets = np.array(targets)\n",
    "    predicts = np.array(predicts)\n",
    "    return metrics.roc_auc_score(targets, predicts), metrics.log_loss(targets, predicts), gauc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps (MPS)\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'dataset_name': 'elec',  # Options: 'ml-10m', 'elec', 'kuairec'\n",
    "    'model_name': 'macgnn',\n",
    "    'runs': 1,\n",
    "    'epoch': 20,\n",
    "    'early_epoch': 4,\n",
    "    'learning_rate': 1e-2,  # Baseline learning rate; tuning scenarios override if needed\n",
    "    'weight_decay': 5e-5,\n",
    "    'batch_size': 1024,\n",
    "    'embed_dim': 10,        # Baseline embedding size; tuning scenarios override for experiments\n",
    "    'recent_len': 20,\n",
    "    'tau': 0.8,\n",
    "    'mlp_dropout': 0.0,\n",
    "    'lr_scheduler': None,   # Options: None, 'cosine', 'steplr'\n",
    "    'lr_scheduler_params': {},\n",
    "    'seed': 2023,\n",
    "    'use_gpu': True,\n",
    "    'cuda_id': 0,\n",
    "    'data_dir': 'data',\n",
    "    'checkpoint_dir': 'checkpoints',\n",
    "    'log_interval': 20,\n",
    "    'test_iter': 50  # Evaluate every N iterations; lower to ~30 for small learning rates (see report.md)\n",
    "}\n",
    "\n",
    "# Device detection with MPS support\n",
    "if torch.cuda.is_available() and config['use_gpu']:\n",
    "    device = torch.device(f\"cuda:{config['cuda_id']}\")\n",
    "    print(f'Using device: {device}')\n",
    "elif torch.backends.mps.is_available() and config['use_gpu']:\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f'Using device: {device} (MPS)')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "Path(config['checkpoint_dir']).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c96a9",
   "metadata": {},
   "source": [
    "## Tuning Scenarios Configuration\n",
    "\n",
    "This notebook contains **8 predefined experimental scenarios** corresponding to the complete experimental design in `report.md`:\n",
    "\n",
    "### Scenario List\n",
    "1. **Baseline**: Original paper configuration (lr=1e-2, embed_dim=10, epoch=20)\n",
    "2. **HighLR_Embed32**: Increased embedding dimension to 32 â­ Verified optimal\n",
    "3. **LowLR_LongEpoch**: Low learning rate with extended training (lr=1e-3, epoch=40)\n",
    "4. **HighLR_Embed32_CosineDrop**: Cosine annealing + strong regularization\n",
    "5. **LowLR_LongEpoch_Step**: StepLR learning rate decay\n",
    "6. **ShortSeq_Tau1**: Short sequence window for sparse data\n",
    "7. **LongSeq_Tau06**: Long sequence window to capture long-term interests\n",
    "8. **HighLR_Embed32_MultiRun**: 3 runs for stability validation\n",
    "\n",
    "### How to Use\n",
    "- **Run all scenarios**: Keep the `tuning_scenarios` list below complete\n",
    "- **Run specific scenarios**: Comment out unwanted scenarios (add `#` before `make_scenario`)\n",
    "- **Run default config only**: Set `tuning_scenarios = []`\n",
    "\n",
    "### Estimated Runtime (Apple Silicon MPS)\n",
    "- Single scenario (20 epochs): ~3-4 minutes\n",
    "- All 8 scenarios: ~40-60 minutes\n",
    "- Recommended: Run scenarios 1-3 first for quick validation, then run others as needed\n",
    "\n",
    "See Chapter 3 of `report.md` for the complete usage guide.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f961d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up tuning scenarios (set to [] to skip automatic sweeps)\n",
    "def make_scenario(name, description, overrides):\n",
    "    return {\n",
    "        'name': name,\n",
    "        'description': description,\n",
    "        'overrides': overrides\n",
    "    }\n",
    "\n",
    "# Each scenario encodes a concrete suggestion from report.md\n",
    "# You can comment out entries to only run a subset.\n",
    "tuning_scenarios = [\n",
    "    make_scenario(\n",
    "        'Baseline',\n",
    "        'Default baseline configuration from original paper: lr=1e-2, embed_dim=10, epoch=20',\n",
    "        {\n",
    "            'learning_rate': 1e-2,\n",
    "            'embed_dim': 10,\n",
    "            'epoch': 20,\n",
    "            'early_epoch': 4\n",
    "        }\n",
    "    ),\n",
    "    make_scenario(\n",
    "        'HighLR_Embed32',\n",
    "        'Keep lr=1e-2 while enlarging the embedding dimension as suggested.',\n",
    "        {\n",
    "            'learning_rate': 1e-2,\n",
    "            'embed_dim': 32,\n",
    "            'epoch': 20\n",
    "        }\n",
    "    ),\n",
    "    make_scenario(\n",
    "        'LowLR_LongEpoch',\n",
    "        'Let lr=1e-3 train longer so smaller steps have time to converge.',\n",
    "        {\n",
    "            'learning_rate': 1e-3,\n",
    "            'embed_dim': 32,\n",
    "            'epoch': 40,\n",
    "            'early_epoch': 8,\n",
    "            'test_iter': 30\n",
    "        }\n",
    "    ),\n",
    "    make_scenario(\n",
    "        'HighLR_Embed32_CosineDrop',\n",
    "        'High learning rate + embed_dim 32 with cosine annealing, dropout, and stronger weight decay.',\n",
    "        {\n",
    "            'learning_rate': 1e-2,\n",
    "            'embed_dim': 32,\n",
    "            'epoch': 25,\n",
    "            'weight_decay': 1e-4,\n",
    "            'mlp_dropout': 0.2,\n",
    "            'lr_scheduler': 'cosine',\n",
    "            'lr_scheduler_params': {\n",
    "                't_max': 25,\n",
    "                'eta_min': 5e-4\n",
    "            },\n",
    "            'test_iter': 40\n",
    "        }\n",
    "    ),\n",
    "    make_scenario(\n",
    "        'LowLR_LongEpoch_Step',\n",
    "        'Lower learning rate with 60 epochs, StepLR decay, and mild dropout to aid convergence.',\n",
    "        {\n",
    "            'learning_rate': 1e-3,\n",
    "            'embed_dim': 32,\n",
    "            'epoch': 60,\n",
    "            'early_epoch': 8,\n",
    "            'mlp_dropout': 0.1,\n",
    "            'lr_scheduler': 'steplr',\n",
    "            'lr_scheduler_params': {\n",
    "                'step_size': 15,\n",
    "                'gamma': 0.5\n",
    "            },\n",
    "            'test_iter': 30\n",
    "        }\n",
    "    ),\n",
    "    make_scenario(\n",
    "        'ShortSeq_Tau1',\n",
    "        'Use a shorter recent window (10) together with tau=1.0 to reduce sparsity noise.',\n",
    "        {\n",
    "            'learning_rate': 1e-2,\n",
    "            'embed_dim': 32,\n",
    "            'epoch': 20,\n",
    "            'recent_len': 10,\n",
    "            'tau': 1.0,\n",
    "            'mlp_dropout': 0.1,\n",
    "            'weight_decay': 1e-4\n",
    "        }\n",
    "    ),\n",
    "    make_scenario(\n",
    "        'LongSeq_Tau06',\n",
    "        'Capture longer-term behavior with recent_len=50 and a smoother tau=0.6.',\n",
    "        {\n",
    "            'learning_rate': 1e-2,\n",
    "            'embed_dim': 32,\n",
    "            'epoch': 30,\n",
    "            'recent_len': 50,\n",
    "            'tau': 0.6,\n",
    "            'mlp_dropout': 0.1,\n",
    "            'weight_decay': 1e-4,\n",
    "            'test_iter': 40\n",
    "        }\n",
    "    ),\n",
    "    make_scenario(\n",
    "        'HighLR_Embed32_MultiRun',\n",
    "        'Run the best-performing HighLR_Embed32 setup three times to report averaged metrics.',\n",
    "        {\n",
    "            'learning_rate': 1e-2,\n",
    "            'embed_dim': 32,\n",
    "            'epoch': 20,\n",
    "            'runs': 3,\n",
    "            'early_epoch': 6,\n",
    "            'test_iter': 40\n",
    "        }\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int, device):\n",
    "    print(f'Set Seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    elif device.type == 'mps':\n",
    "        torch.mps.manual_seed(seed)\n",
    "\n",
    "def load_dataset_assets(dataset_name: str, data_dir: str, device):\n",
    "    # Use pathlib for robust path handling\n",
    "    data_path = Path(data_dir) / f'{dataset_name}.pkl'\n",
    "    if not data_path.exists():\n",
    "        # Try looking in parent directory if not found (common issue)\n",
    "        data_path = Path('..') / 'data' / f'{dataset_name}.pkl'\n",
    "        \n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f'Dataset not found: {data_path}')\n",
    "        \n",
    "    print(f'Loading data from: {data_path}')\n",
    "    with open(data_path, 'rb') as f:\n",
    "        train_set = np.array(pickle.load(f, encoding='latin1'))\n",
    "        test_set = np.array(pickle.load(f, encoding='latin1'))\n",
    "        cate_list = torch.tensor(pickle.load(f, encoding='latin1')).to(device)\n",
    "        u_cluster_list = torch.tensor(pickle.load(f, encoding='latin1')).to(device)\n",
    "        i_cluster_list = torch.tensor(pickle.load(f, encoding='latin1')).to(device)\n",
    "        user_count, item_count, cate_count, u_cluster_num, i_cluster_num = pickle.load(f)\n",
    "\n",
    "    feature_dim = train_set.shape[1] - 1  # subtract label column\n",
    "    if feature_dim % 2 != 0:\n",
    "        raise ValueError(f'Unexpected feature dimension {feature_dim}; cannot infer recent_len')\n",
    "    raw_recent_len = feature_dim // 2 - (u_cluster_num + i_cluster_num + 2)\n",
    "    if raw_recent_len <= 0:\n",
    "        raise ValueError(f'Invalid inferred recent_len={raw_recent_len}. Check dataset preprocessing.')\n",
    "\n",
    "    field_dims = [user_count + 1, item_count + 1, cate_count + 1]\n",
    "    u_cluster_adjusted = u_cluster_num - 1\n",
    "\n",
    "    assets = {\n",
    "        'train_set': train_set,\n",
    "        'test_set': test_set,\n",
    "        'cate_list': cate_list,\n",
    "        'u_cluster_list': u_cluster_list,\n",
    "        'i_cluster_list': i_cluster_list,\n",
    "        'user_count': user_count,\n",
    "        'item_count': item_count,\n",
    "        'cate_count': cate_count,\n",
    "        'u_cluster_num': u_cluster_adjusted,\n",
    "        'i_cluster_num': i_cluster_num,\n",
    "        'field_dims': field_dims,\n",
    "        'raw_recent_len': raw_recent_len,\n",
    "        'u_cluster_num_raw': u_cluster_num,\n",
    "        'i_cluster_num_raw': i_cluster_num\n",
    "    }\n",
    "    return assets\n",
    "\n",
    "def build_dataloaders(config, device):\n",
    "    assets = load_dataset_assets(config['dataset_name'], config['data_dir'], device)\n",
    "    train_data = DatasetBuilder(assets['train_set'], assets['user_count'], assets['item_count'])\n",
    "    test_data = DatasetBuilder(assets['test_set'], assets['user_count'], assets['item_count'])\n",
    "    train_loader = DataLoader(train_data, batch_size=config['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=config['batch_size'])\n",
    "    return assets, train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bdfbf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Comprehensive evaluation suite loaded!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ðŸš€ COMPREHENSIVE EXPERIMENTS SUITE\n",
    "# ==========================================\n",
    "# This section adds:\n",
    "# 1. Multi-model comparison (DeepFM, DIN, DIEN, MacGNN)\n",
    "# 2. Inference time measurement\n",
    "# 3. User group analysis\n",
    "# 4. Ablation studies\n",
    "# 5. Multi-dataset support (elec, kuairec)\n",
    "# ==========================================\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns  # type: ignore[import]\n",
    "except ImportError:\n",
    "    sns = None  # Seaborn is optional; visualizations fall back to matplotlib only\n",
    "\n",
    "# Enhanced evaluation with inference time and user analysis\n",
    "def evaluation_comprehensive(model, data_loader, device, use_gauc=False, measure_time=False, analyze_groups=False):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation with:\n",
    "    - Inference time measurement\n",
    "    - User group performance analysis\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    targets, predicts, user_id_list = [], [], []\n",
    "    inference_times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for fields, target in tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0, desc=\"Evaluating\"):\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            \n",
    "            if measure_time:\n",
    "                if device.type == 'cuda':\n",
    "                    torch.cuda.synchronize()\n",
    "                    start = time.perf_counter()\n",
    "                    y = model(fields)\n",
    "                    torch.cuda.synchronize()\n",
    "                    end = time.perf_counter()\n",
    "                elif device.type == 'mps':\n",
    "                    torch.mps.synchronize()\n",
    "                    start = time.perf_counter()\n",
    "                    y = model(fields)\n",
    "                    torch.mps.synchronize()\n",
    "                    end = time.perf_counter()\n",
    "                else:\n",
    "                    start = time.perf_counter()\n",
    "                    y = model(fields)\n",
    "                    end = time.perf_counter()\n",
    "                inference_times.append((end - start) * 1000)  # ms\n",
    "            else:\n",
    "                y = model(fields)\n",
    "            \n",
    "            user_id_list.extend(fields[:, 0].tolist())\n",
    "            targets.extend(target.tolist())\n",
    "            predicts.extend(y.tolist())\n",
    "    \n",
    "    targets = np.array(targets)\n",
    "    predicts = np.array(predicts)\n",
    "    \n",
    "    # Core metrics\n",
    "    auc = metrics.roc_auc_score(targets, predicts)\n",
    "    logloss = metrics.log_loss(targets, predicts)\n",
    "    gauc = cal_group_auc(targets, predicts, user_id_list) if use_gauc else None\n",
    "    \n",
    "    # Inference time\n",
    "    avg_time_per_batch = np.mean(inference_times) if inference_times else None\n",
    "    avg_time_per_sample = avg_time_per_batch / data_loader.batch_size if avg_time_per_batch else None\n",
    "    \n",
    "    # User group analysis\n",
    "    user_metrics = None\n",
    "    if analyze_groups:\n",
    "        user_metrics = analyze_user_groups(targets, predicts, user_id_list)\n",
    "    \n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'logloss': logloss,\n",
    "        'gauc': gauc,\n",
    "        'inference_time_per_sample_ms': avg_time_per_sample,\n",
    "        'inference_time_per_batch_ms': avg_time_per_batch,\n",
    "        'user_group_metrics': user_metrics\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_user_groups(targets, predicts, user_id_list):\n",
    "    \"\"\"Analyze performance by user activity level\"\"\"\n",
    "    user_data = defaultdict(lambda: {'targets': [], 'predicts': []})\n",
    "\n",
    "    def _to_scalar(value):\n",
    "        \"\"\"Convert tensors/arrays/lists to a python scalar\"\"\"\n",
    "        if 'torch' in globals() and isinstance(value, torch.Tensor):\n",
    "            value = value.detach().cpu().numpy()\n",
    "        arr = np.asarray(value)\n",
    "        if arr.size == 0:\n",
    "            raise ValueError(\"Empty value encountered while analyzing user groups\")\n",
    "        arr = arr.reshape(-1)[0]\n",
    "        if isinstance(arr, np.generic):\n",
    "            return arr.item()\n",
    "        return arr\n",
    "\n",
    "    for uid, t, p in zip(user_id_list, targets, predicts):\n",
    "        uid_scalar = _to_scalar(uid)\n",
    "        t_scalar = float(_to_scalar(t))\n",
    "        p_scalar = float(_to_scalar(p))\n",
    "        user_data[uid_scalar]['targets'].append(t_scalar)\n",
    "        user_data[uid_scalar]['predicts'].append(p_scalar)\n",
    "\n",
    "    # Group by activity (number of interactions)\n",
    "    activities = [(uid, len(data['targets'])) for uid, data in user_data.items()]\n",
    "    activities = sorted(activities, key=lambda x: x[1])\n",
    "\n",
    "    n = len(activities)\n",
    "    cold = set([u[0] for u in activities[:n//3]])\n",
    "    medium = set([u[0] for u in activities[n//3:2*n//3]])\n",
    "    hot = set([u[0] for u in activities[2*n//3:]])\n",
    "\n",
    "    groups = {'cold_start': cold, 'medium_activity': medium, 'high_activity': hot}\n",
    "    result = {}\n",
    "\n",
    "    for name, users in groups.items():\n",
    "        g_targets, g_preds = [], []\n",
    "        for uid in users:\n",
    "            user_history = user_data.get(uid)\n",
    "            if not user_history:\n",
    "                continue\n",
    "            g_targets.extend(user_history['targets'])\n",
    "            g_preds.extend(user_history['predicts'])\n",
    "\n",
    "        if len(g_targets) > 0 and len(set(g_targets)) > 1:\n",
    "            result[name] = {\n",
    "                'auc': roc_auc_score(g_targets, g_preds),\n",
    "                'count': len(g_targets)\n",
    "            }\n",
    "        else:\n",
    "            result[name] = {'auc': None, 'count': len(g_targets)}\n",
    "\n",
    "    return result\n",
    "\n",
    "# Factory function to create models\n",
    "def create_model(model_name, config, assets, device):\n",
    "    \"\"\"Create model instance based on name\"\"\"\n",
    "    field_dims = assets['field_dims']\n",
    "    embed_dim = config['embed_dim']\n",
    "    recent_len = config['recent_len']\n",
    "    raw_recent_len = assets.get('raw_recent_len')\n",
    "    mlp_dropout = config.get('mlp_dropout', 0.0)\n",
    "    \n",
    "    if model_name == 'macgnn':\n",
    "        return MacGNN(\n",
    "            field_dims=field_dims,\n",
    "            u_group_num=assets['u_cluster_num'],\n",
    "            i_group_num=assets['i_cluster_num'],\n",
    "            embed_dim=embed_dim,\n",
    "            recent_len=recent_len,\n",
    "            tau=config['tau'],\n",
    "            device=device,\n",
    "            mlp_dropout=mlp_dropout,\n",
    "            raw_recent_len=raw_recent_len\n",
    "        ).to(device)\n",
    "    \n",
    "    elif model_name == 'deepfm':\n",
    "        return DeepFM(\n",
    "            field_dims=field_dims,\n",
    "            embed_dim=embed_dim,\n",
    "            mlp_dims=(400, 400, 400),\n",
    "            dropout=mlp_dropout\n",
    "        ).to(device)\n",
    "    \n",
    "    elif model_name == 'din':\n",
    "        return DIN(\n",
    "            field_dims=field_dims,\n",
    "            embed_dim=embed_dim,\n",
    "            recent_len=recent_len,\n",
    "            mlp_dropout=mlp_dropout,\n",
    "            raw_recent_len=raw_recent_len\n",
    "        ).to(device)\n",
    "    \n",
    "    elif model_name == 'dien':\n",
    "        return DIEN(\n",
    "            field_dims=field_dims,\n",
    "            embed_dim=embed_dim,\n",
    "            recent_len=recent_len,\n",
    "            mlp_dropout=mlp_dropout,\n",
    "            raw_recent_len=raw_recent_len\n",
    "        ).to(device)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "\n",
    "# Run multi-model comparison\n",
    "def run_model_comparison(config, models_to_test=['macgnn', 'deepfm', 'din', 'dien']):\n",
    "    \"\"\"\n",
    "    Run comprehensive comparison across multiple models\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸš€ MULTI-MODEL COMPARISON EXPERIMENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    assets, train_loader, test_loader = build_dataloaders(config, device)\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in models_to_test:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ðŸ“Š Testing Model: {model_name.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        set_seed(config['seed'], device)\n",
    "        \n",
    "        model = create_model(model_name, config, assets, device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                     lr=config['learning_rate'], \n",
    "                                     weight_decay=config['weight_decay'])\n",
    "        \n",
    "        checkpoint_path = Path(config['checkpoint_dir']) / f\"{model_name}_{config['dataset_name']}_comparison.pt\"\n",
    "        early_stopper = EarlyStopper(config['early_epoch'], str(checkpoint_path))\n",
    "        \n",
    "        # Training\n",
    "        train_simple(model, optimizer, train_loader, test_loader, criterion, device, \n",
    "                    early_stopper, config['epoch'], config['test_iter'], config['log_interval'])\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        \n",
    "        # Comprehensive evaluation\n",
    "        eval_results = evaluation_comprehensive(\n",
    "            model, test_loader, device, \n",
    "            use_gauc=True, \n",
    "            measure_time=True, \n",
    "            analyze_groups=True\n",
    "        )\n",
    "        \n",
    "        results[model_name] = eval_results\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Results for {model_name.upper()}:\")\n",
    "        print(f\"  AUC: {eval_results['auc']:.6f}\")\n",
    "        print(f\"  LogLoss: {eval_results['logloss']:.6f}\")\n",
    "        print(f\"  GAUC: {eval_results['gauc']}\")\n",
    "        print(f\"  Inference Time: {eval_results['inference_time_per_sample_ms']:.4f} ms/sample\")\n",
    "        \n",
    "        if eval_results['user_group_metrics']:\n",
    "            print(f\"\\n  ðŸ‘¥ User Group Performance:\")\n",
    "            for group, metrics in eval_results['user_group_metrics'].items():\n",
    "                auc_str = f\"{metrics['auc']:.4f}\" if metrics['auc'] else \"N/A\"\n",
    "                print(f\"    {group}: AUC={auc_str} (n={metrics['count']})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Simplified training for comparison (no complex scheduling)\n",
    "def train_simple(model, optimizer, train_loader, test_loader, criterion, device, \n",
    "                early_stopper, epochs, test_iter, log_interval):\n",
    "    total_loss = 0.0\n",
    "    now_iter = 0\n",
    "    \n",
    "    for epo in range(epochs):\n",
    "        tk0 = tqdm.tqdm(train_loader, smoothing=0, mininterval=1.0, desc=f\"Epoch {epo+1}/{epochs}\")\n",
    "        \n",
    "        for i, (fields, target) in enumerate(tk0):\n",
    "            model.train()\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            target = target.float().view(-1)\n",
    "            y = model(fields).view(-1)\n",
    "            loss = criterion(y, target)\n",
    "            \n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            now_iter += 1\n",
    "            \n",
    "            if now_iter % test_iter == 0:\n",
    "                results = evaluation_comprehensive(model, test_loader, device, use_gauc=False)\n",
    "                if not early_stopper.is_continuable(model, results['auc'], results['logloss']):\n",
    "                    print(f\"Early stopping: best AUC={early_stopper.best_auc:.6f}\")\n",
    "                    return\n",
    "            \n",
    "            if (i+1) % log_interval == 0:\n",
    "                tk0.set_postfix(loss=total_loss / log_interval)\n",
    "                total_loss = 0\n",
    "\n",
    "\n",
    "print(\"âœ… Comprehensive evaluation suite loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "run_experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main experiment runner: loads data, trains model, evaluates performance\n",
    "def run_experiment(config):\n",
    "    assets, train_loader, test_loader = build_dataloaders(config, device)\n",
    "    field_dims = assets['field_dims']\n",
    "    u_cluster_num = assets['u_cluster_num']\n",
    "    i_cluster_num = assets['i_cluster_num']\n",
    "\n",
    "    auc_runs, logloss_runs, gauc_runs = [], [], []\n",
    "    checkpoint_dir = Path(config['checkpoint_dir'])\n",
    "\n",
    "    for run_idx in range(config['runs']):\n",
    "        if config['runs'] != 1:\n",
    "            set_seed(config['seed'] + run_idx, device)\n",
    "        else:\n",
    "            set_seed(config['seed'], device)\n",
    "            \n",
    "        print(f'########### Run {run_idx} ###########')\n",
    "        print(f\"Dataset: {config['dataset_name']}\")\n",
    "\n",
    "        model = MacGNN(\n",
    "            field_dims=field_dims,\n",
    "            u_group_num=u_cluster_num,\n",
    "            i_group_num=i_cluster_num,\n",
    "            embed_dim=config['embed_dim'],\n",
    "            recent_len=config['recent_len'],\n",
    "            tau=config['tau'],\n",
    "            device=device,\n",
    "            mlp_dropout=config.get('mlp_dropout', 0.0),\n",
    "            raw_recent_len=assets.get('raw_recent_len')\n",
    "        ).to(device)\n",
    "\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "        checkpoint_path = checkpoint_dir / f\"{config['model_name']}_{config['dataset_name']}_run{run_idx}.pt\"\n",
    "        \n",
    "        early_stopper = EarlyStopper(num_trials=config['early_epoch'], save_path=str(checkpoint_path))\n",
    "\n",
    "        scheduler = None\n",
    "        scheduler_name = config.get('lr_scheduler')\n",
    "        if scheduler_name:\n",
    "            scheduler_name = scheduler_name.lower()\n",
    "            scheduler_params = config.get('lr_scheduler_params', {}) or {}\n",
    "            if scheduler_name == 'cosine':\n",
    "                t_max = scheduler_params.get('t_max', config['epoch'])\n",
    "                eta_min = scheduler_params.get('eta_min', 0)\n",
    "                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
    "            elif scheduler_name == 'steplr':\n",
    "                step_size = scheduler_params.get('step_size', max(1, config['epoch'] // 3))\n",
    "                gamma = scheduler_params.get('gamma', 0.1)\n",
    "                scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported lr_scheduler: {scheduler_name}\")\n",
    "            print(f\"Using LR scheduler: {scheduler_name} with params {scheduler_params}\")\n",
    "\n",
    "        train(\n",
    "            model,\n",
    "            optimizer,\n",
    "            train_loader,\n",
    "            test_loader,\n",
    "            criterion,\n",
    "            device,\n",
    "            early_stopper,\n",
    "            epochs=config['epoch'],\n",
    "            test_iter=config['test_iter'],\n",
    "            log_interval=config['log_interval'],\n",
    "            scheduler=scheduler\n",
    "        )\n",
    "\n",
    "        # Load best model (state_dict)\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        \n",
    "        auc, logloss, gauc = evaluation(model, test_loader, device, use_gauc=True)\n",
    "        print(f'Test AUC: {auc:.6f}, Test Logloss: {logloss:.6f}, Test GAUC: {gauc}')\n",
    "        auc_runs.append(auc)\n",
    "        logloss_runs.append(logloss)\n",
    "        gauc_runs.append(gauc)\n",
    "\n",
    "    results = {\n",
    "        'auc_mean': float(np.mean(auc_runs)),\n",
    "        'auc_std': float(np.std(auc_runs)),\n",
    "        'logloss_mean': float(np.mean(logloss_runs)),\n",
    "        'logloss_std': float(np.std(logloss_runs)),\n",
    "        'gauc_mean': float(np.mean(gauc_runs)) if all(g is not None for g in gauc_runs) else None,\n",
    "        'gauc_std': float(np.std([g for g in gauc_runs if g is not None])) if all(g is not None for g in gauc_runs) else None\n",
    "    }\n",
    "    print('\\n===== Summary =====')\n",
    "    print(f\"Test AUC: {results['auc_mean']:.6f} Â± {results['auc_std']:.6f}\")\n",
    "    print(f\"Test Logloss: {results['logloss_mean']:.6f} Â± {results['logloss_std']:.6f}\")\n",
    "    if results['gauc_mean'] is not None:\n",
    "        print(f\"Test GAUC: {results['gauc_mean']:.6f} Â± {results['gauc_std']:.6f}\")\n",
    "    else:\n",
    "        print('Test GAUC: Not enough positive/negative pairs per user to compute.')\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "execute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Scenario: Baseline =====\n",
      "Default baseline configuration from original paper: lr=1e-2, embed_dim=10, epoch=20\n",
      "Loading data from: data/elec.pkl\n",
      "Set Seed: 2023\n",
      "########### Run 0 ###########\n",
      "Dataset: elec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:09<00:00, 29.69it/s]loss=0.518]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:07<00:00, 34.16it/s]loss=0.501]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:09<00:00, 27.86it/s] loss=0.477]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:08<00:00, 33.49it/s] loss=0.479]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:09<00:00, 28.51it/s] loss=0.475]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:12<00:00,  3.65it/s, loss=0.475]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:08<00:00, 33.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:08<00:00, 32.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:07<00:00, 33.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:07<00:00, 34.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:07<00:00, 33.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:08<00:00, 33.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:07<00:00, 33.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:07<00:00, 33.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:07<00:00, 33.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.8407214380436754, best logloss: 0.49479261600881563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:07<00:00, 34.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.840721, Test Logloss: 0.494793, Test GAUC: 0.84212\n",
      "\n",
      "===== Summary =====\n",
      "Test AUC: 0.840721 Â± 0.000000\n",
      "Test Logloss: 0.494793 Â± 0.000000\n",
      "Test GAUC: 0.842120 Â± 0.000000\n",
      "\n",
      "===== Scenario: HighLR_Embed32 =====\n",
      "Keep lr=1e-2 while enlarging the embedding dimension as suggested.\n",
      "Loading data from: data/elec.pkl\n",
      "Set Seed: 2023\n",
      "########### Run 0 ###########\n",
      "Dataset: elec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.57it/s]loss=0.518]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 15.45it/s]loss=0.504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.66it/s] loss=0.495]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:16<00:00, 15.96it/s] loss=0.484]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.58it/s] loss=0.483]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:37<00:00,  2.73it/s, loss=0.483]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:15<00:00, 17.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.68it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.8379914572315588, best logloss: 0.5003113641201549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.837991, Test Logloss: 0.500311, Test GAUC: 0.83849\n",
      "\n",
      "===== Summary =====\n",
      "Test AUC: 0.837991 Â± 0.000000\n",
      "Test Logloss: 0.500311 Â± 0.000000\n",
      "Test GAUC: 0.838490 Â± 0.000000\n",
      "\n",
      "===== Scenario: LowLR_LongEpoch =====\n",
      "Let lr=1e-3 train longer so smaller steps have time to converge.\n",
      "Loading data from: data/elec.pkl\n",
      "Set Seed: 2023\n",
      "########### Run 0 ###########\n",
      "Dataset: elec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 21.94it/s]loss=0.675]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.35it/s]loss=0.553]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.63it/s]loss=0.506]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.00it/s] loss=0.497]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.14it/s] loss=0.488]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 21.00it/s] loss=0.475]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.45it/s] loss=0.473]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 19.93it/s] loss=0.467]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [02:05<00:00,  2.13it/s, loss=0.467]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 19.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:20<00:00, 13.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:19<00:00, 14.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.68it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:18<00:00, 14.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:19<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.8410203136446445, best logloss: 0.4968673485653507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.841020, Test Logloss: 0.496867, Test GAUC: 0.84118\n",
      "\n",
      "===== Summary =====\n",
      "Test AUC: 0.841020 Â± 0.000000\n",
      "Test Logloss: 0.496867 Â± 0.000000\n",
      "Test GAUC: 0.841180 Â± 0.000000\n",
      "\n",
      "===== Scenario: HighLR_Embed32_CosineDrop =====\n",
      "High learning rate + embed_dim 32 with cosine annealing, dropout, and stronger weight decay.\n",
      "Loading data from: data/elec.pkl\n",
      "Set Seed: 2023\n",
      "########### Run 0 ###########\n",
      "Dataset: elec\n",
      "Using LR scheduler: cosine with params {'t_max': 25, 'eta_min': 0.0005}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.57it/s]loss=0.579]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:18<00:00, 14.55it/s]loss=0.515]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.03it/s] loss=0.506]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.05it/s] loss=0.506]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:15<00:00, 17.24it/s] loss=0.496]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.76it/s] loss=0.495]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:47<00:00,  2.47it/s, loss=0.493]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:14<00:00, 18.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:14<00:00, 18.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 19.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 15.07it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.8303281713257822, best logloss: 0.5127783227896092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.830328, Test Logloss: 0.512778, Test GAUC: 0.83135\n",
      "\n",
      "===== Summary =====\n",
      "Test AUC: 0.830328 Â± 0.000000\n",
      "Test Logloss: 0.512778 Â± 0.000000\n",
      "Test GAUC: 0.831350 Â± 0.000000\n",
      "\n",
      "===== Scenario: LowLR_LongEpoch_Step =====\n",
      "Lower learning rate with 60 epochs, StepLR decay, and mild dropout to aid convergence.\n",
      "Loading data from: data/elec.pkl\n",
      "Set Seed: 2023\n",
      "########### Run 0 ###########\n",
      "Dataset: elec\n",
      "Using LR scheduler: steplr with params {'step_size': 15, 'gamma': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 22.20it/s]loss=0.677]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:14<00:00, 18.34it/s]loss=0.557]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.65it/s]loss=0.508]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 19.61it/s] loss=0.498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.88it/s] loss=0.489]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 19.99it/s] loss=0.477]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.09it/s] loss=0.476]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 20.55it/s] loss=0.47] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [02:08<00:00,  2.06it/s, loss=0.469]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 20.96it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:16<00:00, 15.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 15.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 15.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 15.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 15.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 15.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.8404314877736565, best logloss: 0.5024632727186514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.840431, Test Logloss: 0.502463, Test GAUC: 0.84048\n",
      "\n",
      "===== Summary =====\n",
      "Test AUC: 0.840431 Â± 0.000000\n",
      "Test Logloss: 0.502463 Â± 0.000000\n",
      "Test GAUC: 0.840480 Â± 0.000000\n",
      "\n",
      "===== Scenario: ShortSeq_Tau1 =====\n",
      "Use a shorter recent window (10) together with tau=1.0 to reduce sparsity noise.\n",
      "Loading data from: data/elec.pkl\n",
      "Set Seed: 2023\n",
      "########### Run 0 ###########\n",
      "Dataset: elec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 20.27it/s]loss=0.527]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.31it/s]loss=0.512]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.80it/s] loss=0.503]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 22.23it/s] loss=0.494]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.36it/s] loss=0.498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:31<00:00,  2.92it/s, loss=0.495]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.832874735812156, best logloss: 0.4999579734894762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.832875, Test Logloss: 0.499958, Test GAUC: 0.83362\n",
      "\n",
      "===== Summary =====\n",
      "Test AUC: 0.832875 Â± 0.000000\n",
      "Test Logloss: 0.499958 Â± 0.000000\n",
      "Test GAUC: 0.833620 Â± 0.000000\n",
      "\n",
      "===== Scenario: LongSeq_Tau06 =====\n",
      "Capture longer-term behavior with recent_len=50 and a smoother tau=0.6.\n",
      "Loading data from: data/elec.pkl\n",
      "Set Seed: 2023\n",
      "########### Run 0 ###########\n",
      "Dataset: elec\n",
      "[MacGNN] recent_len 50 exceeds dataset limit 20; using 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 21.83it/s]loss=0.579]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.72it/s]loss=0.517]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.27it/s] loss=0.506]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.17it/s] loss=0.504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.52it/s] loss=0.494]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.23it/s] loss=0.49] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:39<00:00,  2.68it/s, loss=0.489]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 20.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 21.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.8339395295193265, best logloss: 0.499434048831001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.833940, Test Logloss: 0.499434, Test GAUC: 0.83476\n",
      "\n",
      "===== Summary =====\n",
      "Test AUC: 0.833940 Â± 0.000000\n",
      "Test Logloss: 0.499434 Â± 0.000000\n",
      "Test GAUC: 0.834760 Â± 0.000000\n",
      "\n",
      "===== Scenario: HighLR_Embed32_MultiRun =====\n",
      "Run the best-performing HighLR_Embed32 setup three times to report averaged metrics.\n",
      "Loading data from: data/elec.pkl\n",
      "Set Seed: 2023\n",
      "########### Run 0 ###########\n",
      "Dataset: elec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.40it/s]loss=0.577]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.37it/s]loss=0.509]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.55it/s] loss=0.498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:16<00:00, 16.48it/s] loss=0.495]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.91it/s] loss=0.484]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 20.46it/s] loss=0.484]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:43<00:00,  2.56it/s, loss=0.483]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 21.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 15.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.07it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.65it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 19.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 21.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:16<00:00, 16.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.8418673861996202, best logloss: 0.4969569730493468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.841867, Test Logloss: 0.496957, Test GAUC: 0.84302\n",
      "Set Seed: 2024\n",
      "########### Run 1 ###########\n",
      "Dataset: elec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.70it/s]loss=0.583]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.25it/s]loss=0.508]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.54it/s] loss=0.501]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.55it/s] loss=0.487]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.89it/s] loss=0.483]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.04it/s] loss=0.485]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:33<00:00,  2.85it/s, loss=0.48] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.75it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:14<00:00, 18.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.65it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:14<00:00, 18.81it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:18<00:00, 14.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:17<00:00, 14.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.8407433738290752, best logloss: 0.5088511094594428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.840743, Test Logloss: 0.508851, Test GAUC: 0.84153\n",
      "Set Seed: 2025\n",
      "########### Run 2 ###########\n",
      "Dataset: elec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.99it/s]loss=0.578]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.61it/s]loss=0.502]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.71it/s] loss=0.501]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.80it/s] loss=0.499]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.75it/s] loss=0.494]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.63it/s] loss=0.486]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:33<00:00,  2.83it/s, loss=0.491]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:12<00:00, 21.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:13<00:00, 19.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: best auc: 0.8391531380084929, best logloss: 0.4998830437213509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.839153, Test Logloss: 0.499883, Test GAUC: 0.83962\n",
      "\n",
      "===== Summary =====\n",
      "Test AUC: 0.840588 Â± 0.001114\n",
      "Test Logloss: 0.501897 Â± 0.005060\n",
      "Test GAUC: 0.841390 Â± 0.001392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Baseline': {'auc_mean': 0.8407214380436754,\n",
       "  'auc_std': 0.0,\n",
       "  'logloss_mean': 0.49479261600881563,\n",
       "  'logloss_std': 0.0,\n",
       "  'gauc_mean': 0.84212,\n",
       "  'gauc_std': 0.0},\n",
       " 'HighLR_Embed32': {'auc_mean': 0.8379914572315588,\n",
       "  'auc_std': 0.0,\n",
       "  'logloss_mean': 0.5003113641201549,\n",
       "  'logloss_std': 0.0,\n",
       "  'gauc_mean': 0.83849,\n",
       "  'gauc_std': 0.0},\n",
       " 'LowLR_LongEpoch': {'auc_mean': 0.8410203136446445,\n",
       "  'auc_std': 0.0,\n",
       "  'logloss_mean': 0.4968673485653507,\n",
       "  'logloss_std': 0.0,\n",
       "  'gauc_mean': 0.84118,\n",
       "  'gauc_std': 0.0},\n",
       " 'HighLR_Embed32_CosineDrop': {'auc_mean': 0.8303281713257822,\n",
       "  'auc_std': 0.0,\n",
       "  'logloss_mean': 0.5127783227896092,\n",
       "  'logloss_std': 0.0,\n",
       "  'gauc_mean': 0.83135,\n",
       "  'gauc_std': 0.0},\n",
       " 'LowLR_LongEpoch_Step': {'auc_mean': 0.8404314877736565,\n",
       "  'auc_std': 0.0,\n",
       "  'logloss_mean': 0.5024632727186514,\n",
       "  'logloss_std': 0.0,\n",
       "  'gauc_mean': 0.84048,\n",
       "  'gauc_std': 0.0},\n",
       " 'ShortSeq_Tau1': {'auc_mean': 0.832874735812156,\n",
       "  'auc_std': 0.0,\n",
       "  'logloss_mean': 0.4999579734894762,\n",
       "  'logloss_std': 0.0,\n",
       "  'gauc_mean': 0.83362,\n",
       "  'gauc_std': 0.0},\n",
       " 'LongSeq_Tau06': {'auc_mean': 0.8339395295193265,\n",
       "  'auc_std': 0.0,\n",
       "  'logloss_mean': 0.499434048831001,\n",
       "  'logloss_std': 0.0,\n",
       "  'gauc_mean': 0.83476,\n",
       "  'gauc_std': 0.0},\n",
       " 'HighLR_Embed32_MultiRun': {'auc_mean': 0.8405879660123962,\n",
       "  'auc_std': 0.0011135227891316182,\n",
       "  'logloss_mean': 0.5018970420767135,\n",
       "  'logloss_std': 0.005060287361210845,\n",
       "  'gauc_mean': 0.84139,\n",
       "  'gauc_std': 0.001391569856912192}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_results = {}\n",
    "if tuning_scenarios:\n",
    "    for scenario in tuning_scenarios:\n",
    "        overrides = scenario.get('overrides', {})\n",
    "        scenario_config = config.copy()\n",
    "        scenario_config.update(overrides)\n",
    "        print(f\"\\n===== Scenario: {scenario['name']} =====\")\n",
    "        if scenario.get('description'):\n",
    "            print(scenario['description'])\n",
    "        scenario_results[scenario['name']] = run_experiment(scenario_config)\n",
    "else:\n",
    "    scenario_results['default'] = run_experiment(config)\n",
    "\n",
    "results = scenario_results\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cee3a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_auc</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>test_logloss</th>\n",
       "      <th>logloss_std</th>\n",
       "      <th>test_gauc</th>\n",
       "      <th>gauc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LowLR_LongEpoch</th>\n",
       "      <td>0.841020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496867</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.84118</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.840721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494793</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.84212</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighLR_Embed32_MultiRun</th>\n",
       "      <td>0.840588</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.501897</td>\n",
       "      <td>0.00506</td>\n",
       "      <td>0.84139</td>\n",
       "      <td>0.001392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowLR_LongEpoch_Step</th>\n",
       "      <td>0.840431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502463</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.84048</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighLR_Embed32</th>\n",
       "      <td>0.837991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500311</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.83849</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LongSeq_Tau06</th>\n",
       "      <td>0.833940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499434</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.83476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShortSeq_Tau1</th>\n",
       "      <td>0.832875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499958</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.83362</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighLR_Embed32_CosineDrop</th>\n",
       "      <td>0.830328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.512778</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.83135</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           test_auc   auc_std  test_logloss  logloss_std  \\\n",
       "LowLR_LongEpoch            0.841020  0.000000      0.496867      0.00000   \n",
       "Baseline                   0.840721  0.000000      0.494793      0.00000   \n",
       "HighLR_Embed32_MultiRun    0.840588  0.001114      0.501897      0.00506   \n",
       "LowLR_LongEpoch_Step       0.840431  0.000000      0.502463      0.00000   \n",
       "HighLR_Embed32             0.837991  0.000000      0.500311      0.00000   \n",
       "LongSeq_Tau06              0.833940  0.000000      0.499434      0.00000   \n",
       "ShortSeq_Tau1              0.832875  0.000000      0.499958      0.00000   \n",
       "HighLR_Embed32_CosineDrop  0.830328  0.000000      0.512778      0.00000   \n",
       "\n",
       "                           test_gauc  gauc_std  \n",
       "LowLR_LongEpoch              0.84118  0.000000  \n",
       "Baseline                     0.84212  0.000000  \n",
       "HighLR_Embed32_MultiRun      0.84139  0.001392  \n",
       "LowLR_LongEpoch_Step         0.84048  0.000000  \n",
       "HighLR_Embed32               0.83849  0.000000  \n",
       "LongSeq_Tau06                0.83476  0.000000  \n",
       "ShortSeq_Tau1                0.83362  0.000000  \n",
       "HighLR_Embed32_CosineDrop    0.83135  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize all scenario results for quick comparison\n",
    "if 'results' in globals() and results:\n",
    "    summary_df = (\n",
    "        pd.DataFrame.from_dict(results, orient='index')\n",
    "        .rename(columns={\n",
    "            'auc_mean': 'test_auc',\n",
    "            'auc_std': 'auc_std',\n",
    "            'logloss_mean': 'test_logloss',\n",
    "            'logloss_std': 'logloss_std',\n",
    "            'gauc_mean': 'test_gauc',\n",
    "            'gauc_std': 'gauc_std'\n",
    "        })\n",
    "        [['test_auc', 'auc_std', 'test_logloss', 'logloss_std', 'test_gauc', 'gauc_std']]\n",
    "    )\n",
    "    display(summary_df.sort_values('test_auc', ascending=False))\n",
    "else:\n",
    "    print('No results to summarize yet.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1b06f",
   "metadata": {},
   "source": [
    "## Experiment Complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70588d40",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Ablation Studies\n",
    "\n",
    "Test MacGNN with components removed to validate their contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f51fa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ablation study suite loaded!\n"
     ]
    }
   ],
   "source": [
    "# Ablation variants\n",
    "class MacGNN_NoMacro(MacGNN):\n",
    "    \"\"\"MacGNN without macro embeddings (ablation study)\"\"\"\n",
    "    def forward(self, x):\n",
    "        # Only use micro embeddings\n",
    "        offset = 0\n",
    "        user_embedding = self.user_embed(x[:, offset])\n",
    "        \n",
    "        # Skip macro neighbors\n",
    "        offset = 1 + self.i_group_num + self.u_group_num\n",
    "        user_recent_block = x[:, offset: offset + self.raw_recent_len]\n",
    "        offset += self.raw_recent_len\n",
    "        \n",
    "        item_embedding = self.item_embed(x[:, offset])\n",
    "        offset = offset + 1 + self.u_group_num + self.i_group_num\n",
    "        item_recent_block = x[:, offset: offset + self.raw_recent_len]\n",
    "        \n",
    "        user_recent = user_recent_block[:, -self.recent_len:] if self.recent_len < self.raw_recent_len else user_recent_block\n",
    "        item_recent = item_recent_block[:, -self.recent_len:] if self.recent_len < self.raw_recent_len else item_recent_block\n",
    "        \n",
    "        user_recent_mask = (user_recent > 0).float().unsqueeze(-1)\n",
    "        item_recent_mask = (item_recent > 0).float().unsqueeze(-1)\n",
    "        \n",
    "        user_recent_embedding = self.item_embed(user_recent)\n",
    "        item_recent_embedding = self.user_embed(item_recent)\n",
    "        \n",
    "        user_recent_ws = torch.mul(user_recent_embedding, user_recent_mask).sum(dim=1)\n",
    "        item_recent_ws = torch.mul(item_recent_embedding, item_recent_mask).sum(dim=1)\n",
    "        \n",
    "        # Simplified MLP input (no macro features)\n",
    "        concated = torch.cat([user_embedding, item_embedding, user_recent_ws, item_recent_ws], dim=1)\n",
    "        \n",
    "        # Adjust MLP for different input size\n",
    "        if not hasattr(self, 'simple_mlp'):\n",
    "            self.simple_mlp = nn.Sequential(\n",
    "                nn.Linear(self.user_embed.embedding_dim * 4, 200),\n",
    "                Dice(),\n",
    "                nn.Linear(200, 80),\n",
    "                Dice(),\n",
    "                nn.Linear(80, 1)\n",
    "            ).to(concated.device)\n",
    "        \n",
    "        output = self.simple_mlp(concated)\n",
    "        return torch.sigmoid(output.squeeze(1))\n",
    "\n",
    "\n",
    "def run_ablation_study(config):\n",
    "    \"\"\"\n",
    "    Ablation study: test MacGNN with different components removed\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ”¬ ABLATION STUDY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    variants = {\n",
    "        'MacGNN (Full)': 'macgnn',\n",
    "        'MacGNN w/o Macro': 'macgnn_nomacro',\n",
    "    }\n",
    "    \n",
    "    assets, train_loader, test_loader = build_dataloaders(config, device)\n",
    "    results = {}\n",
    "    \n",
    "    for variant_name, variant_key in variants.items():\n",
    "        print(f\"\\n Testing: {variant_name}\")\n",
    "        set_seed(config['seed'], device)\n",
    "        \n",
    "        if variant_key == 'macgnn':\n",
    "            model = create_model('macgnn', config, assets, device)\n",
    "        elif variant_key == 'macgnn_nomacro':\n",
    "            model = MacGNN_NoMacro(\n",
    "                field_dims=assets['field_dims'],\n",
    "                u_group_num=assets['u_cluster_num'],\n",
    "                i_group_num=assets['i_cluster_num'],\n",
    "                embed_dim=config['embed_dim'],\n",
    "                recent_len=config['recent_len'],\n",
    "                tau=config['tau'],\n",
    "                device=device,\n",
    "                mlp_dropout=config.get('mlp_dropout', 0.0),\n",
    "                raw_recent_len=assets.get('raw_recent_len')\n",
    "            ).to(device)\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], \n",
    "                                     weight_decay=config['weight_decay'])\n",
    "        \n",
    "        checkpoint_path = Path(config['checkpoint_dir']) / f\"{variant_key}_ablation.pt\"\n",
    "        early_stopper = EarlyStopper(config['early_epoch'], str(checkpoint_path))\n",
    "        \n",
    "        train_simple(model, optimizer, train_loader, test_loader, criterion, device,\n",
    "                    early_stopper, config['epoch'], config['test_iter'], config['log_interval'])\n",
    "        \n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        eval_results = evaluation_comprehensive(model, test_loader, device, use_gauc=True, measure_time=True)\n",
    "        \n",
    "        results[variant_name] = eval_results\n",
    "        print(f\"  AUC: {eval_results['auc']:.6f}, Time: {eval_results['inference_time_per_sample_ms']:.4f}ms\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ… Ablation study suite loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439363c",
   "metadata": {},
   "source": [
    "## ðŸ“Š Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec9ece7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Visualization functions loaded!\n"
     ]
    }
   ],
   "source": [
    "# Visualization functions\n",
    "def plot_model_comparison(results, save_path=None):\n",
    "    \"\"\"\n",
    "    Create comprehensive comparison plots\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    models = list(results.keys())\n",
    "    \n",
    "    # 1. AUC Comparison\n",
    "    aucs = [results[m]['auc'] for m in models]\n",
    "    axes[0, 0].bar(models, aucs, color='skyblue')\n",
    "    axes[0, 0].set_title('AUC Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('AUC')\n",
    "    axes[0, 0].set_ylim([min(aucs) * 0.98, max(aucs) * 1.02])\n",
    "    for i, v in enumerate(aucs):\n",
    "        axes[0, 0].text(i, v + 0.0005, f'{v:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. LogLoss Comparison (lower is better)\n",
    "    logloss = [results[m]['logloss'] for m in models]\n",
    "    axes[0, 1].bar(models, logloss, color='coral')\n",
    "    axes[0, 1].set_title('LogLoss Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('LogLoss')\n",
    "    for i, v in enumerate(logloss):\n",
    "        axes[0, 1].text(i, v + 0.002, f'{v:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. Inference Time Comparison\n",
    "    times = [results[m]['inference_time_per_sample_ms'] for m in models]\n",
    "    axes[1, 0].bar(models, times, color='lightgreen')\n",
    "    axes[1, 0].set_title('Inference Time (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('ms per sample')\n",
    "    for i, v in enumerate(times):\n",
    "        axes[1, 0].text(i, v + 0.0001, f'{v:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. User Group Performance\n",
    "    if all(results[m]['user_group_metrics'] for m in models):\n",
    "        groups = ['cold_start', 'medium_activity', 'high_activity']\n",
    "        x = np.arange(len(groups))\n",
    "        width = 0.2\n",
    "        \n",
    "        for i, model in enumerate(models):\n",
    "            group_aucs = [results[model]['user_group_metrics'][g]['auc'] \n",
    "                         if results[model]['user_group_metrics'][g]['auc'] else 0 \n",
    "                         for g in groups]\n",
    "            axes[1, 1].bar(x + i*width, group_aucs, width, label=model)\n",
    "        \n",
    "        axes[1, 1].set_title('Performance by User Group', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('AUC')\n",
    "        axes[1, 1].set_xticks(x + width)\n",
    "        axes[1, 1].set_xticklabels(groups, rotation=15)\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"ðŸ“Š Plots saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_comparison_table(results):\n",
    "    \"\"\"\n",
    "    Create a beautiful comparison table\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for model, res in results.items():\n",
    "        data.append({\n",
    "            'Model': model.upper(),\n",
    "            'AUC': f\"{res['auc']:.6f}\",\n",
    "            'LogLoss': f\"{res['logloss']:.6f}\",\n",
    "            'GAUC': f\"{res['gauc']:.5f}\" if res['gauc'] else \"N/A\",\n",
    "            'Time (ms)': f\"{res['inference_time_per_sample_ms']:.4f}\" if res['inference_time_per_sample_ms'] else \"N/A\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Sort by AUC descending\n",
    "    df = df.sort_values('AUC', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"âœ… Visualization functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41428051",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Run All Experiments\n",
    "\n",
    "Execute this cell to run the complete experimental suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11caaf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸŽ¯ COMPREHENSIVE EXPERIMENTS - MacGNN vs Baselines\n",
      "================================================================================\n",
      "Dataset: elec\n",
      "Device: mps\n",
      "Embedding Dim: 32\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Step 1/3: Running Multi-Model Comparison...\n",
      "\n",
      "======================================================================\n",
      "ðŸš€ MULTI-MODEL COMPARISON EXPERIMENT\n",
      "======================================================================\n",
      "Loading data from: data/elec.pkl\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š Testing Model: MACGNN\n",
      "==================================================\n",
      "Set Seed: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.51it/s]loss=0.518]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.86it/s]loss=0.503]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.62it/s] loss=0.495]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.65it/s] loss=0.484]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.93it/s] loss=0.483]\n",
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:24<00:00,  3.15it/s, loss=0.483]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.91it/s]loss=0.58]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.89it/s]loss=0.449]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 25.19it/s] loss=0.466]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.57it/s] loss=0.47] \n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.64it/s] loss=0.469]\n",
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:23<00:00,  3.20it/s, loss=0.461]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.58it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.11it/s]loss=0.437]\n",
      "Epoch 3/10:  25%|â–ˆâ–ˆâ–Œ       | 67/266 [00:29<01:27,  2.26it/s, loss=0.437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: best AUC=0.837595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Results for MACGNN:\n",
      "  AUC: 0.837595\n",
      "  LogLoss: 0.503814\n",
      "  GAUC: 0.83804\n",
      "  Inference Time: 0.0326 ms/sample\n",
      "\n",
      "  ðŸ‘¥ User Group Performance:\n",
      "    cold_start: AUC=0.8334 (n=38284)\n",
      "    medium_activity: AUC=0.8344 (n=61886)\n",
      "    high_activity: AUC=0.8396 (n=174152)\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š Testing Model: DEEPFM\n",
      "==================================================\n",
      "Set Seed: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 148.63it/s]oss=0.687]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 139.93it/s]oss=0.646]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 150.61it/s]loss=0.632]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 148.71it/s]loss=0.625]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 142.32it/s]loss=0.623]\n",
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:14<00:00, 17.82it/s, loss=0.622]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 143.63it/s]]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 156.96it/s]oss=0.612]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 147.16it/s]oss=0.617]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 142.19it/s]loss=0.618]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 150.45it/s]loss=0.615]\n",
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:13<00:00, 19.25it/s, loss=0.616]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 148.87it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 143.69it/s]oss=0.603]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 143.38it/s]oss=0.603]\n",
      "Epoch 3/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 117/266 [00:07<00:09, 15.30it/s, loss=0.603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: best AUC=0.691888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 140.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Results for DEEPFM:\n",
      "  AUC: 0.691888\n",
      "  LogLoss: 0.611605\n",
      "  GAUC: 0.69069\n",
      "  Inference Time: 0.0018 ms/sample\n",
      "\n",
      "  ðŸ‘¥ User Group Performance:\n",
      "    cold_start: AUC=0.6872 (n=38284)\n",
      "    medium_activity: AUC=0.6900 (n=61886)\n",
      "    high_activity: AUC=0.6936 (n=174152)\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š Testing Model: DIN\n",
      "==================================================\n",
      "Set Seed: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:03<00:00, 70.53it/s]loss=0.613]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:02<00:00, 124.92it/s]oss=0.614]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:02<00:00, 116.08it/s]loss=0.609]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:02<00:00, 118.90it/s]loss=0.608]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:02<00:00, 128.80it/s]loss=0.613]\n",
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:19<00:00, 13.61it/s, loss=0.605]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:02<00:00, 120.48it/s]]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:02<00:00, 113.32it/s]oss=0.605]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:02<00:00, 120.60it/s]loss=0.607]\n",
      "Epoch 2/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 133/266 [00:09<00:09, 13.45it/s, loss=0.607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: best AUC=0.694576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:02<00:00, 117.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Results for DIN:\n",
      "  AUC: 0.694576\n",
      "  LogLoss: 0.611843\n",
      "  GAUC: 0.691\n",
      "  Inference Time: 0.0029 ms/sample\n",
      "\n",
      "  ðŸ‘¥ User Group Performance:\n",
      "    cold_start: AUC=0.6906 (n=38284)\n",
      "    medium_activity: AUC=0.6923 (n=61886)\n",
      "    high_activity: AUC=0.6959 (n=174152)\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š Testing Model: DIEN\n",
      "==================================================\n",
      "Set Seed: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:06<00:00, 39.15it/s]loss=0.605]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:05<00:00, 50.53it/s]loss=0.608]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:05<00:00, 45.17it/s] loss=0.605]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:05<00:00, 51.95it/s] loss=0.609]\n",
      "Epoch 1/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 199/266 [00:51<00:17,  3.90it/s, loss=0.609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: best AUC=0.694131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:05<00:00, 52.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Results for DIEN:\n",
      "  AUC: 0.694131\n",
      "  LogLoss: 0.613782\n",
      "  GAUC: 0.69203\n",
      "  Inference Time: 0.0127 ms/sample\n",
      "\n",
      "  ðŸ‘¥ User Group Performance:\n",
      "    cold_start: AUC=0.6911 (n=38284)\n",
      "    medium_activity: AUC=0.6926 (n=61886)\n",
      "    high_activity: AUC=0.6951 (n=174152)\n",
      "\n",
      "ðŸ”¬ Step 2/3: Running Ablation Study...\n",
      "\n",
      "======================================================================\n",
      "ðŸ”¬ ABLATION STUDY\n",
      "======================================================================\n",
      "Loading data from: data/elec.pkl\n",
      "\n",
      " Testing: MacGNN (Full)\n",
      "Set Seed: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 22.86it/s]loss=0.518]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.96it/s]loss=0.503]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.77it/s] loss=0.495]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.34it/s] loss=0.484]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.29it/s] loss=0.483]\n",
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:24<00:00,  3.14it/s, loss=0.483]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.04it/s]loss=0.58]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.58it/s]loss=0.449]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 23.62it/s] loss=0.467]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.25it/s] loss=0.471]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.31it/s] loss=0.468]\n",
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [01:24<00:00,  3.14it/s, loss=0.461]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.34it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.42it/s]loss=0.437]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:11<00:00, 24.14it/s] loss=0.451]\n",
      "Epoch 3/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 117/266 [00:45<00:58,  2.56it/s, loss=0.451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: best AUC=0.837798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:10<00:00, 24.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AUC: 0.837798, Time: 0.0332ms\n",
      "\n",
      " Testing: MacGNN w/o Macro\n",
      "Set Seed: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 136.86it/s]]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 143.72it/s]oss=0.681]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:02<00:00, 132.80it/s]loss=0.682]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 148.44it/s]loss=0.681]\n",
      "Epoch 1/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 199/266 [00:11<00:03, 16.92it/s, loss=0.681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: best AUC=0.749930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 137.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AUC: 0.749930, Time: 0.0017ms\n",
      "\n",
      "ðŸ“Š Step 3/3: Creating Visualizations...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>GAUC</th>\n",
       "      <th>Time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MACGNN</td>\n",
       "      <td>0.837595</td>\n",
       "      <td>0.503814</td>\n",
       "      <td>0.83804</td>\n",
       "      <td>0.0326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIN</td>\n",
       "      <td>0.694576</td>\n",
       "      <td>0.611843</td>\n",
       "      <td>0.69100</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIEN</td>\n",
       "      <td>0.694131</td>\n",
       "      <td>0.613782</td>\n",
       "      <td>0.69203</td>\n",
       "      <td>0.0127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEEPFM</td>\n",
       "      <td>0.691888</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>0.69069</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model       AUC   LogLoss     GAUC Time (ms)\n",
       "0  MACGNN  0.837595  0.503814  0.83804    0.0326\n",
       "1     DIN  0.694576  0.611843  0.69100    0.0029\n",
       "2    DIEN  0.694131  0.613782  0.69203    0.0127\n",
       "3  DEEPFM  0.691888  0.611605  0.69069    0.0018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Plots saved to checkpoints/comparison_elec.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Results saved to checkpoints/results_elec.csv\n",
      "\n",
      "================================================================================\n",
      "ðŸŽ‰ ALL EXPERIMENTS COMPLETED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive experiment configuration\n",
    "comprehensive_config = {\n",
    "    'dataset_name': 'elec',  # Change to 'elec' or 'kuairec' as needed\n",
    "    'model_name': 'macgnn',\n",
    "    'runs': 1,\n",
    "    'epoch': 10,  # Reduced for faster comparison\n",
    "    'early_epoch': 3,\n",
    "    'learning_rate': 1e-2,\n",
    "    'weight_decay': 5e-5,\n",
    "    'batch_size': 1024,\n",
    "    'embed_dim': 32,  # Use larger embedding for better performance\n",
    "    'recent_len': 20,\n",
    "    'tau': 0.8,\n",
    "    'mlp_dropout': 0.0,\n",
    "    'seed': 2023,\n",
    "    'use_gpu': True,\n",
    "    'cuda_id': 0,\n",
    "    'data_dir': 'data',\n",
    "    'checkpoint_dir': 'checkpoints',\n",
    "    'log_interval': 20,\n",
    "    'test_iter': 50\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ¯ COMPREHENSIVE EXPERIMENTS - MacGNN vs Baselines\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Dataset: {comprehensive_config['dataset_name']}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Embedding Dim: {comprehensive_config['embed_dim']}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Multi-Model Comparison\n",
    "print(\"\\nðŸ“Š Step 1/3: Running Multi-Model Comparison...\")\n",
    "comparison_results = run_model_comparison(\n",
    "    comprehensive_config, \n",
    "    models_to_test=['macgnn', 'deepfm', 'din', 'dien']\n",
    ")\n",
    "\n",
    "# 2. Ablation Study\n",
    "print(\"\\nðŸ”¬ Step 2/3: Running Ablation Study...\")\n",
    "ablation_results = run_ablation_study(comprehensive_config)\n",
    "\n",
    "# 3. Visualization\n",
    "print(\"\\nðŸ“Š Step 3/3: Creating Visualizations...\")\n",
    "comparison_df = create_comparison_table(comparison_results)\n",
    "display(comparison_df)\n",
    "\n",
    "plot_model_comparison(\n",
    "    comparison_results, \n",
    "    save_path=f\"checkpoints/comparison_{comprehensive_config['dataset_name']}.png\"\n",
    ")\n",
    "\n",
    "# Save results to CSV\n",
    "comparison_df.to_csv(f\"checkpoints/results_{comprehensive_config['dataset_name']}.csv\", index=False)\n",
    "print(f\"\\nâœ… Results saved to checkpoints/results_{comprehensive_config['dataset_name']}.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ‰ ALL EXPERIMENTS COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
